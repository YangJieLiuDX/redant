L0 范数：向量中非 0 元素的个数。如果用 L0 范数来规则化一个参数矩阵 W 的话，就是希望 W 的大部分元素是0，即让参数 W 是稀疏的。

例如判断某种病的患病率时，最初有1000个特征，建模后参数经过稀疏化，最终只有5个特征的参数是非零的，那么就可以说影响患病率的主要就是这5个特征。

L1 范数：向量中各元素绝对值之和，也叫稀疏规则算子（Lasso regularization）。任何的规则化算子，如果在 W=0 不可微，且可分解为求和形式，那么这个规则化算子就可以实现稀疏。W 的 L1 范数是绝对值，在 W=0 处不可微。既然 L0 可以实现稀疏，为什么不用 L0，而要用 L1 呢？一是因为 L0 范数很难优化求解（NP难问题），二是 L1 范数是 L0 范数的最优凸近似，而且它比 L0 范数要容易优化求解。

参数稀疏化的应用：

1. 特征选择：实现特征的自动选择，去除无用特征。稀疏化可以去掉这些无用特征，将特征对应的权重置为零。
2. 可解释性：如判断某种病的患病率时，最初有 1000 个特征，建模后参数经过稀疏化后只有 5 个特征的参数是非零的，就可以说影响患病率的主要是这 5 个特征。

L2 范数：向量中各元素平方和的平方根，可叫岭回归（Ridge Regression），也叫权值衰减（weight decay），主要用于解决过拟合问题。让 L2 范数的规则项最小，可以使得 W 的每个元素都很小，都接近于 0，但与 L1 范数不同，它不会让它等于 0，而是接近于 0。

