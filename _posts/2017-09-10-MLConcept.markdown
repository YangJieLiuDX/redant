---
layout:     post
title:      "机器学习简单概念和常见问题"
subtitle:   "那些关于机器学习的面试题"
date:       2017-09-10 16:30:00
author:     "林佩勤"
header-img: "img/post-bg.jpg"
tags:
    - 机器学习
---

> 掌握好基本概念才能深入学习
>

## 前言

本文将围绕着机器学习面试中常见的题目进行展开，聊聊那些关于机器学习的知识和概念。

---

## 正文

**什么是梯度下降算法**

梯度下降算法即GD算法，也称最速下降法，是求解无约束最优化问题的一种常用方法。它是一种迭代算法，每一步都需要求解目标函数的梯度向量。

梯度下降法首先需要选取适当的初值x0，不断迭代，更新x的值，进行目标函数的极小化，直至收敛。由于负梯度方向是使函数值下降最快的方向，在迭代的每一步，以负梯度方向更新x的值，从而达到减少函数值的目的。

当目标函数是凸函数时，梯度下降法的解是全局最优解。一般情况下，其解不保证是全局最优解。梯度下降法的收敛速度也未必是最快的。

**梯度下降算法有什么缺点**

虽然GD算法简单易理解，但其至少有两个明显的缺点：

1. 工作量大。由于机器学习应用一般数据集较大，所以这个时候如果要算目标函数的精确导数，则需要花很长的时间去扫描整个数据集，而且每次只能走一小步，所以要很多步才能够收敛，这样的工作量无疑是巨大的
2. 如果我们不小心陷入了鞍点或较差的局部最优点，那GD算法就跑不出来了

针于这两个缺点，我们可以采用随机最速下降法（Stochastic Gradient Descent，即SGD）解决。

## 后记

只有掌握好了基础，才能进一步学习，所以无论学习哪一门学问，都要重视基础，打好基础。
